---
title: "Class_09_Mini_Project"
author: "Hayoung A15531571"
date: "10/26/2021"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



To get started let's read the data!

```{r}
#we tell R what file we want here
fna.data <- "WisconsinCancer.csv"

#making sure to format the data correctly
wisc.df <- read.csv(fna.data, row.names=1)

#finally let's view our data
head(wisc.df)
```

When we look at our data so far, we realize that we don't wnat the first row which tells us right away if something is malignant or benign. 

```{r}
# We can use -1 here to remove the first column
wisc.data <- wisc.df[,-1]
```

```{r}
# Create diagnosis vector for later 
diagnosis <- as.factor(wisc.df$diagnosis)
```

Let's move onto the questions!

>Q1. How many observations are in this dataset?

```{r}
#here we read all the data (minus the first diagnosis column)
dim(wisc.data)
```
There are 569 rows (or different biopsies to analyze). Each biopsy has 30 elements to it (30 rows).

>Q2. How many of the observations have a malignant diagnosis?

```{r}
#here we can use our diagnosis vector to see how many malignant, or "M" results we have
length(grep(pattern = "M", x = diagnosis))
```
There are 212 malignant results in this data set (out of 569 biopsies)


>Q3. How many variables/features in the data are suffixed with _mean?

```{r}
#first we have to be able to read the column names
features <- colnames(wisc.df)
length(grep(pattern = "_mean", x = features))

```
There are 10 variables with "_mean" in the variable name.


# Performing PCA

```{r}
# Check column means and standard deviations
colMeans(wisc.data)

apply(wisc.data,2,sd)
```

Let's execute PCA now
```{r}
# Perform PCA on wisc.data by completing the following code
wisc.pr <- prcomp(wisc.data, scale = TRUE)

# Look at summary of results
summary(wisc.pr)
```

>Q4. From your results, what proportion of the original variance is captured by the first principal components (PC1)?

From our summary above we can see that 44.27% of the variance is captured by PC1

>Q5. How many principal components (PCs) are required to describe at least 70% of the original variance in the data?

To describe at least 70% of variance, we need 3 principal components

>Q6. How many principal components (PCs) are required to describe at least 90% of the original variance in the data?

To describe at least 90% of variance, we need 7 principal components


#Now let's try plotting this out

```{r}
biplot(wisc.pr)

as.factor(diagnosis)
```

>Q7. What stands out to you about this plot? Is it easy or difficult to understand? Why?

It is very messy and unable to be read. Even when we pop it out in the larger browser, there are so many points that it is impossible to really read or understand. Row names are being used as labels which makes it hard to read, considering how many rows we have. 

Let's try this again, we are after the score plot (ex: PC1 vs PC2)

```{r}
# Scatter plot observations by components 1 and 2
plot(wisc.pr$x[,1:2], col = diagnosis , 
     xlab = "PC1", ylab = "PC2")
```

>Q8. Generate a similar plot for principal components 1 and 3. What do you notice about these plots?

```{r}
# Scatter plot observations by components 1 and 3
plot(wisc.pr$x[,1], wisc.pr$x[,3], col = diagnosis , 
     xlab = "PC1", ylab = "PC3")
```

#Now let's try using ggplot to make a nicer looking plot

```{r}
# Create a data.frame for ggplot
df <- as.data.frame(wisc.pr$x)
df$diagnosis <- diagnosis

# Load the ggplot2 package
library(ggplot2)

# Make a scatter plot colored by diagnosis
ggplot(df) + 
  aes(PC1, PC2, col = diagnosis) + 
  geom_point()
```

#Variance

```{r}
# Calculate variance of each component
pr.var <- wisc.pr$sdev^2
head(pr.var)
```

```{r}
# Variance explained by each principal component: pve
pve <- pr.var / sum(pr.var)

# Plot variance explained for each principal component
plot(pve, xlab = "Principal Component", 
     ylab = "Proportion of Variance Explained", 
     ylim = c(0, 1), type = "o")
```

An alternative graph!

```{r}
# data driven y-axis
barplot(pve, ylab = "Precent of Variance Explained",
     names.arg=paste0("PC",1:length(pve)), las=2, axes = FALSE)
axis(2, at=pve, labels=round(pve,2)*100 )
```


>Q9. For the first principal component, what is the component of the loading vector (i.e. wisc.pr$rotation[,1]) for the feature concave.points_mean?

```{r}
wisc.pr$rotation["concave.points_mean",1]
```

The component of the loading vector for the feature concave.points_mean is -0.26085376.

>Q10. What is the minimum number of principal components required to explain 80% of the variance of the data?

```{r}
var <- summary(wisc.pr)
var$importance[2,]
```


We need at least 5 principal components to explain 80% variance of the data.


#Hierarchal Clustering

```{r}
# Scale the wisc.data data using the "scale()" function
data.scaled <- scale(wisc.data)
```

```{r}
#Calculate the (Euclidean) distances between all pairs of observations
data.dist <- dist(data.scaled)
```

```{r}
#Create a hierarchical clustering model using complete linkage.
wisc.hclust <- hclust(data.dist, method = "complete")
```

>Q11. Using the plot() and abline() functions, what is the height at which the clustering model has 4 clusters?

```{r}
plot(wisc.hclust)
#not too sure how exactly to calcuate where it cuts off, eyeballed it for now
abline(h = 19.5, col="red", lty=2)
```

#Selecting number of clusters

```{r}
wisc.hclust.clusters <- cutree(wisc.hclust, k = 4)

#We can use the table() function to compare the cluster membership to the actual diagnoses.
table(wisc.hclust.clusters, diagnosis)
```

>Q12. Can you find a better cluster vs diagnoses match by cutting into a different number of clusters between 2 and 10?

```{r}
#Let's try out different cluster groups
wisc.hclust.clusters2 <- cutree(wisc.hclust, k = 2)
table(wisc.hclust.clusters2, diagnosis)

wisc.hclust.clusters3 <- cutree(wisc.hclust, k = 3)
table(wisc.hclust.clusters3, diagnosis)

wisc.hclust.clusters5 <- cutree(wisc.hclust, k = 5)
table(wisc.hclust.clusters5, diagnosis)

wisc.hclust.clusters6 <- cutree(wisc.hclust, k = 6)
table(wisc.hclust.clusters6, diagnosis)

wisc.hclust.clusters7 <- cutree(wisc.hclust, k = 7)
table(wisc.hclust.clusters7, diagnosis)

wisc.hclust.clusters8 <- cutree(wisc.hclust, k = 8)
table(wisc.hclust.clusters8, diagnosis)

wisc.hclust.clusters9 <- cutree(wisc.hclust, k = 9)
table(wisc.hclust.clusters9, diagnosis)

wisc.hclust.clusters10 <- cutree(wisc.hclust, k = 10)
table(wisc.hclust.clusters10, diagnosis)
```

With 6-10 clusters, the results are almsost exactly the same to one another, we can rule those out. 

```{r}
wisc.hclust.clusters2 <- cutree(wisc.hclust, k = 2)
table(wisc.hclust.clusters2, diagnosis)

wisc.hclust.clusters3 <- cutree(wisc.hclust, k = 3)
table(wisc.hclust.clusters3, diagnosis)

#this is our original
wisc.hclust.clusters <- cutree(wisc.hclust, k = 4)
table(wisc.hclust.clusters, diagnosis)

wisc.hclust.clusters5 <- cutree(wisc.hclust, k = 5)
table(wisc.hclust.clusters5, diagnosis)
```

Having 3 clusters gives a better cluster vs. diagnosis match because we can see in this table that cluster 1 represents almost all the data (560/569). We can see here that there are 355 benign cellsa nd 205 malignant ones. 

>Q13. Which method gives your favorite results for the same data.dist dataset? Explain your reasoning.

```{r}
wisc.hclust13 <- hclust(data.dist, method = "ward.D2")
plot(wisc.hclust13)
```

This gives 3 clusters, like we decided on in the previous question. This gives us the grouping that we want. 


#Combining Methods

We take the results of our PCA analysis and cluster in this space

```{r}
summary(wisc.pr)
```

```{r}
#First we have to create something with at least 90% of variance explained for
wisc.pr.hclust <- hclust(dist(wisc.pr$x[,1:3] ),
                         method = "ward.D2")
```

Plotting the dendeogram
```{r}
plot(wisc.pr.hclust)
abline(h=60, col="red")
```

Cut the tree into k=2 groups
```{r}
grps <- cutree(wisc.pr.hclust, k=2)
table(grps)
```

Cross table compare of diagnosis and my cluster groups

```{r}
table(diagnosis, grps)
```

```{r}
plot(wisc.pr$x[,1:2], col=diagnosis)
```

```{r}
g <- as.factor(grps)
levels(g)

g <- relevel(g,2)
levels(g)

# Plot using our re-ordered factor 
plot(wisc.pr$x[,1:2], col=g)
```

```{r}
## Use the distance along the first 7 PCs for clustering i.e. wisc.pr$x[, 1:7]
wisc.pr.hclust <- hclust(dist(wisc.pr$x[,1:7] ),
                         method = "ward.D2")
```

```{r}
wisc.pr.hclust.clusters <- cutree(wisc.pr.hclust, k=2)
```


>Q15. How well does the newly created model with four clusters separate out the two diagnoses?

```{r}
# Compare to actual diagnoses
table(wisc.pr.hclust.clusters, diagnosis)
```
The newly created model sorts once again benign/malignant tumors pretty well. A little better than our previous sorting but honestly still pretty similar. 

>Q16. How well do the k-means and hierarchical clustering models you created in previous sections (i.e. before PCA) do in terms of separating the diagnoses? Again, use the table() function to compare the output of each model (wisc.km$cluster and wisc.hclust.clusters) with the vector containing the actual diagnoses.

```{r}
#this was from the optional part 4 but have to create a wisc.km
wisc.km <- kmeans(wisc.data, centers= 2, nstart= 20)

table(wisc.km$cluster, diagnosis)
table(wisc.hclust.clusters, diagnosis)
```

From our  wisc.hclust.clusters (hierarchal) data, we can see that there are more clusters (4), and provide mostly better results of malignant vs benign. Cluster 1 has 12/165 showing benigb, cluster 3 has 343/383 showing benign, and cluster 4 has 2/2 showing malignant. These results could lead to less false positives. But cluster 3 shows 2/7 as benign, this one cluster is not as defined (in terms of malignant vs. benign).

For our k-means, we have 2 clusters with pretty good separation of benign vs. malignant. Cluster 1 has 130/131 showing to be malignant, and Cluster 2 shows 356/438 to be benign. Personally I think the k-means data is better to look at just as a table, it's Cluster 1 is very accurate.

#Sensitivity/Specificity

>Q17. Which of your analysis procedures resulted in a clustering model with the best specificity? How about sensitivity?

```{r}
#Calculating for sensitivity
130 / (130+82)
165 / (165+40+5+2)

#Calculating for Specificity
356 / (356+1)
343 / (343+12)
```
The use of hierarchical clustering is better for sensitivity

The use of k-means is better for specificity

#Prediction

```{r}
#url <- "new_samples.csv"
url <- "https://tinyurl.com/new-samples-CSV"
new <- read.csv(url)
npc <- predict(wisc.pr, newdata=new)
npc
```

```{r}
plot(wisc.pr$x[,1:2], col=g)
points(npc[,1], npc[,2], col="blue", pch=16, cex=3)
text(npc[,1], npc[,2], c(1,2), col="white")
```

>Q18. Which of these new patients should we prioritize for follow up based on your results?

We would prioritize patient 2 because their clustering/data looks more like the (mostly) malignant patients (more like cluster 1 which had mostly malignant tumors in our previous Wisconsin data).

```{r}
sessionInfo()
```

