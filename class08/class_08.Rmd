---
title: "Machine Learning 1"
author: "Hayoung A15531571"
date: "10/21/2021"
output: html_document
---

First up is clustering methods

#Kmeans clustering

The function in base R to do Kmeans clustering is called `kmeans()`

Generate some example data for clustering where we know what the answer should be
rnorm() gives a random set of normalized data. In this case 30 values centered around -3 and 3

```{r}
tmp <- c(rnorm(30,-3), rnorm(30,3))
x <-cbind(x=tmp, y=rev(tmp))
plot(x)
```

> Q. Can we use kmeans() to cluster this data? setting k 2 and nstart to 20?

```{r}
km <- kmeans(x, centers = 2, nstart = 20)
km
```

> Q. How many points are in each cluster?

```{r}
km$size
```

> Q. What 'component' of your result object details cluster assignment/membership?

```{r}
km$cluster
```

> Q. What 'component' of your result object details cluster center?

```{r}
km$centers
```

> Q. Plot x colored by the kmeans cluster assignment and add cluster centers as blue points

```{r}
plot(x, col=km$cluster)
points(km$centers, col="blue", pch=15, cex=2)
```

#Hierarchical Clustering

A big limitation with kmeans() is that we have to tell it K (the number of clusters we want).

Analyze this data with hclust()

Demonstrate use of dist(), hclust(), plot() and cutree() functions to do clustern,
Generate denfrograms and return cluster assignment/membership vector...

```{r}
hc <- hclust(dist(x))
hc
```

There is a plot method for hclust result objects. Let's see it

```{r}
plot(hc)
```

To get our cluster membership vector we have to do a bit more work, we have to "cut" the tree where we think it makes sense. For this cute the 'cutree()' function

```{r}
cutree(hc, h=6)
```

You can also call 'cutree' setting k = the number of grps/clusters that you want

```{r}
grps <- cutree(hc, k=2)
```

Make our results plot

```{r}
plot(x, col=grps)
```

Now to get started on the rest of the PCA work for this class

```{r}
url <- "https://tinyurl.com/UK-foods"
x <- read.csv(url)
```

> Q1. How many rows and colums are there in this data set?

```{r}
ncol(x)
nrow(x)
dim(x)
```
There are 5 columns and 17 rows of data in this set

```{r}
View(x)
```

But we have an extra column! To fix this we do the following

```{r}
rownames(x) <- x[,1]
x <- x[,-1]
head(x)
```
And it works :)) BUT if we run it again then we lose countries one by one, so there's another way to do it

```{r}
x <- read.csv("https://tinyurl.com/UK-foods", row.names=1)
head(x)
```

> Q2. Which approach to solving the "row-names problem' mentioned above is preferred/why? Is one approach more robust than another under certain circumstances?

I would prefer to use the second method because while both do the same thing initially, the first method could potentially delete actual data that is needed if we accidentally run it again. Meanwhile the second method, no matter how many times it is run, will always result in the end product that we desire. 

Let's try a barplot now!

```{r}
barplot(as.matrix(x), beside=T, col=rainbow(nrow(x)))
```

> Q3. What can we change in the code to change the above plot into one column for each country?

```{r}
barplot(as.matrix(x), beside=FALSE, col=rainbow(nrow(x)))
```

All we did was make the argument 'beside=FALSE', which caused the data to stack instead of be placed side by side.

> Q5. Generating all pairwise plots may help somewhat. Can you make sense of the following code and resulting figure? What does it mean if a given point lies on the diagonal for a given plot?

Now we will make some pairwise plots

```{r}
pairs(x, col=rainbow(10), pch=16)
```

It plots each country against each other country. For example, in the first row the y-axis is England, and the x-axis is the corresponding countries (Wales, Scotland, N. Ireland).

So, if a point value is on the diagnol, it means that the data for both countries being compared is either the same or very similar. 

> Q6. What is the main differences between N. Ireland and the other countries of the UK in terms of this data-set?

To find the main differences, we look at the data points that are not on the diagnol.
When comparing N. Ireland to the other countries, the dark blue point is off the diagnol when comparing against all 3 countries and the orange point is off when comparing with England and Wales (still slightly off for Scotland). 
N. Ireland consumes more fresh potatoes (blue dot is above the diagnol) and less fresh fruit (orange dot is below the diagnol) than the other countries.

#PCA to the resuce!

The main function in base R for PCA is 'prcomp()'
This wants the transpose of our data.

```{r}
pca <- prcomp(t(x))
summary(pca)
```

```{r}
attributes(pca)
```


> Q7. Complete the code below to generate a plot of PC1 vs PC2. The second line adds text labels over the data points.

```{r}
# Plot PC1 vs PC2
plot(pca$x[,1], pca$x[,2], xlab="PC1", ylab="PC2", xlim=c(-270,500))
text(pca$x[,1], pca$x[,2], colnames(x))
```

> Q8. Customize your plot so that the colors of the country names match the colors in our UK and Ireland map and table at start of this document.

```{r}
plot(pca$x[,1], pca$x[,2], xlab="PC1", ylab="PC2", xlim=c(-270,500))
text(pca$x[,1], pca$x[,2], colnames(x), col=rainbow(8))
```

Calculate variation

```{r}
v <- round( pca$sdev^2/sum(pca$sdev^2) * 100 )
v
```

```{r}
## or the second row here...
z <- summary(pca)
z$importance
```

Now lets make a new barplot with this information

```{r}
barplot(v, xlab="Principal Component", ylab="Percent Variation")
```

Lets focus on PC1 as it accounts for > 90% of variance 

```{r}
par(mar=c(10, 3, 0.35, 0))
barplot( pca$rotation[,1], las=2 )
```

> Q9: Generate a similar ‘loadings plot’ for PC2. What two food groups feature prominantely and what does PC2 maninly tell us about?

```{r}
par(mar=c(10, 3, 0.35, 0))
barplot( pca$rotation[,2], las=2 )
```

Soft drinks and Fresh potatoes are most distinguishable. 
PC2 explains the second highest percentage of variation. In this case Fresh_potatoes and Soft_drinks were the most important for PC2.


Let's make a biplot!
```{r}
biplot(pca)
```


#Let's try PCA with some new data!

```{r}
url2 <- "https://tinyurl.com/expression-CSV"
rna.data <- read.csv(url2, row.names=1)
head(rna.data)
```

> Q10: How many genes and samples are in this data set?

```{r}
ngenes <- nrow(rna.data)
nsamples <- ncol(rna.data)
ngenes
nsamples
```

There are 100 genes and 10 samples per gene (1000 samples total)

Let's continue and use PCA to plot this data

```{r}
pca <- prcomp(t(rna.data), scale=TRUE)
 
## Simple unpolished plot of pc1 and pc2
plot(pca$x[,1], pca$x[,2], xlab="PC1", ylab="PC2")
```

```{r}
summary(pca)
```

New plot time

```{r}
plot(pca, main="Quick scree plot")
```

```{r}
## Variance captured per PC 
pca.var <- pca$sdev^2

## Percent variance is often more informative to look at 
pca.var.per <- round(pca.var/sum(pca.var)*100, 1)
pca.var.per
```

Then let's generate our own scree-plot

```{r}
barplot(pca.var.per, main="Scree Plot", 
        names.arg = paste0("PC", 1:10),
        xlab="Principal Component", ylab="Percent Variation")
```

Next we pretty it up

We will have a vector of colors for wt and ko samples
```{r}
colvec <- colnames(rna.data)
colvec[grep("wt", colvec)] <- "red"
colvec[grep("ko", colvec)] <- "blue"

plot(pca$x[,1], pca$x[,2], col=colvec, pch=16,
     xlab=paste0("PC1 (", pca.var.per[1], "%)"),
     ylab=paste0("PC2 (", pca.var.per[2], "%)"))

text(pca$x[,1], pca$x[,2], labels = colnames(rna.data), pos=c(rep(4,5), rep(2,5)))
```

Let's go back to using ggplot!

```{r}
library(ggplot2)
df <- as.data.frame(pca$x)

#a basic plot
ggplot(df) + 
  aes(PC1, PC2) +
  geom_point()
  
```

Let's make this pretty too

```{r}
# Add a 'wt' and 'ko' "condition" column
df$samples <- colnames(rna.data) 
df$condition <- substr(colnames(rna.data),1,2)

p <- ggplot(df) + 
        aes(PC1, PC2, label=samples, col=condition) + 
        geom_label(show.legend = FALSE)
p
```

And some more 

```{r}
p + labs(title="PCA of RNASeq Data",
       subtitle = "PC1 clealy seperates wild-type from knock-out samples",
       x=paste0("PC1 (", pca.var.per[1], "%)"),
       y=paste0("PC2 (", pca.var.per[2], "%)"),
       caption="BIMM143 example data") +
     theme_bw()
```

OPTIONAL
Let's find the top 10 measurements

```{r}
loading_scores <- pca$rotation[,1]

## Find the top 10 measurements (genes) that contribute
## most to PC1 in either direction (+ or -)
gene_scores <- abs(loading_scores) 
gene_score_ranked <- sort(gene_scores, decreasing=TRUE)

## show the names of the top 10 genes
top_10_genes <- names(gene_score_ranked[1:10])
top_10_genes 
```

finsihed


